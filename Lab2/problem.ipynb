{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:53:58.358017Z", "iopub.status.busy": "2024-05-15T03:53:58.356648Z", "iopub.status.idle": "2024-05-15T03:54:04.294020Z", "shell.execute_reply": "2024-05-15T03:54:04.290936Z"}, "executionInfo": {"elapsed": 1293, "status": "ok", "timestamp": 1711646935952, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "48UH6zEyaSc8"}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from tqdm import tqdm\n", "from scipy import stats\n", "from scipy.spatial.distance import cosine\n", "from typing import List, Dict, Tuple"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:54:04.306483Z", "iopub.status.busy": "2024-05-15T03:54:04.305409Z", "iopub.status.idle": "2024-05-15T03:54:04.323974Z", "shell.execute_reply": "2024-05-15T03:54:04.321234Z"}, "executionInfo": {"elapsed": 7, "status": "ok", "timestamp": 1711646804012, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "ZVdb62fRyhTn"}, "outputs": [], "source": ["def load_vocab_dict(path: str) -> Tuple[List[str], Dict[str, int]]:\n", "    \"\"\"\n", "    Reads a vocabulary list from a file and creates a dictionary mapping each word to its index.\n", "\n", "    Args:\n", "        path (str): The file path to the vocabulary list.\n", "\n", "    Returns:\n", "        Tuple[List[str], Dict[str, int]]: A tuple containing the list of vocabulary words and a dictionary\n", "                                          mapping each word to its index.\n", "    \"\"\"\n", "    vocab = open(path).read().strip().split('\\n')\n", "    return vocab, {word: idx for idx, word in enumerate(vocab)}"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:54:04.334311Z", "iopub.status.busy": "2024-05-15T03:54:04.333601Z", "iopub.status.idle": "2024-05-15T03:54:04.347593Z", "shell.execute_reply": "2024-05-15T03:54:04.344843Z"}, "executionInfo": {"elapsed": 6, "status": "ok", "timestamp": 1711646804013, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "hkJ7fQifz532"}, "outputs": [], "source": ["def read_corpus(path: str) -> List[str]:\n", "    \"\"\"Reads the corpus from a file, excluding the last empty entry if the file ends with a newline.\n", "\n", "    Args:\n", "        path (str): The file path to the corpus.\n", "\n", "    Returns:\n", "        List[str]: A list of strings, each representing a line from the file.\n", "    \"\"\"\n", "    return open(path).read().strip().split('\\n')"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:54:04.359092Z", "iopub.status.busy": "2024-05-15T03:54:04.358095Z", "iopub.status.idle": "2024-05-15T03:54:04.385190Z", "shell.execute_reply": "2024-05-15T03:54:04.382283Z"}, "executionInfo": {"elapsed": 5, "status": "ok", "timestamp": 1711646804013, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "_cgReXf9FIl2"}, "outputs": [], "source": ["def counting(corpus: List[str], V: List[str], V_C: List[str], V_set: Dict[str, int], V_C_set: Dict[str, int], w: int) -> np.ndarray:\n", "    \"\"\"\n", "    Generates a co-occurrence (counting) matrix from the given corpus, considering specified vocabularies and a window size.\n", "\n", "    Args:\n", "        corpus (List[str]): The corpus as a list of sentences.\n", "        V (List[str]): The list of vocabulary words.\n", "        V_C (List[str]): The list of context vocabulary words.\n", "        V_set (Dict[str, int]): A dictionary mapping vocabulary words to their indices.\n", "        V_C_set (Dict[str, int]): A dictionary mapping context vocabulary words to their indices.\n", "        w (int): The window size for context.\n", "\n", "    Returns:\n", "        np.ndarray: A 2D NumPy array representing the co-occurrence matrix with dimensions (len(V), len(V_C)).\n", "    \"\"\"\n", "    # Initialize the matrix to hold word vectors\n", "    C = np.zeros((len(V), len(V_C)), dtype=float)\n", "\n", "    for line in tqdm(corpus): # Iterate over each word in the original dataset\n", "        # Append start and end tokens to the sentence\n", "        words = ['<s>'] + line.split(' ') + ['</s>']\n", "        length = len(words)\n", "\n", "        for idx, word in enumerate(words): # Iterate over each word in the current sentence\n", "            # Skip '<s>' and '</s>', as they are not real words\n", "            if idx > 0 and idx < length - 1 and word in V_set:\n", "                # Iterate over left and right context words within the window w\n", "                context_words = words[max(idx-w,0):idx] + words[idx+1:min(idx+w+1,length)]\n", "\n", "                # Constructs a co-occurrence matrix by iterating over context words\n", "                # within a specified range and increments counts in the matrix\n", "                # for each word-context pair found in a predefined vocabulary.\n", "                # It quantifies the relationship between words and their context in a corpus,\n", "                # essential for analyzing word associations.\n", "\n", "                ### BEGIN SOLUTION\n", "                for context_word in context_words:\n", "                    if context_word in V_C_set:\n", "                      C[V_set[word]][V_C_set[context_word]]  = C[V_set[word]][V_C_set[context_word]] + 1\n", "                \n", "                \n", "                \n", "                ### END SOLUTION\n", "    return C"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:54:04.396043Z", "iopub.status.busy": "2024-05-15T03:54:04.395092Z", "iopub.status.idle": "2024-05-15T03:54:04.415250Z", "shell.execute_reply": "2024-05-15T03:54:04.412298Z"}, "executionInfo": {"elapsed": 500, "status": "ok", "timestamp": 1711646943804, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "_KAL4m9SDyKA"}, "outputs": [], "source": ["def eval_word_similarity(C: np.ndarray, V_set: Dict[str, int], path: str) -> float:\n", "    \"\"\"\n", "    Evaluates word similarity by comparing a calculated similarity matrix against a gold standard dataset.\n", "\n", "    Args:\n", "        C (np.ndarray): A 2D NumPy array where rows represent words and columns represent their vector embeddings.\n", "        V_set (Dict[str, int]): A dictionary mapping words to their indices in the matrix C.\n", "        path (str): The file path to the gold standard dataset.\n", "\n", "    Returns:\n", "        float: The Spearman correlation coefficient between the gold standard similarity scores and the calculated scores.\n", "    \"\"\"\n", "    # Read the gold standard data, skipping the header and the last empty line if present\n", "    gold = [line.split('\\t') for line in open(path).read().strip().split('\\n')[1:]]\n", "\n", "    # Prepare gold scores and similarity scores\n", "    y = [float(line[2]) for line in gold]  # Extract gold standard similarity scores\n", "    x = [\n", "        1 - cosine(C[V_set[word_1], :], C[V_set[word_2], :]) if word_1 in V_set and word_2 in V_set else 0\n", "        for word_1, word_2, _ in gold\n", "    ]\n", "\n", "    # Calculate and return Spearman correlation\n", "    return stats.spearmanr(x, y, axis=None).correlation"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2024-05-15T03:54:04.426343Z", "iopub.status.busy": "2024-05-15T03:54:04.425383Z", "iopub.status.idle": "2024-05-15T03:58:21.423364Z", "shell.execute_reply": "2024-05-15T03:58:21.420302Z"}, "executionInfo": {"elapsed": 114004, "status": "ok", "timestamp": 1711646918013, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "tKH1dmT2D8V4", "outputId": "cbca5f46-8a0f-4da5-9a89-51835eb1dcf8"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 997898/997898 [04:10<00:00, 3976.21it/s]\n"]}], "source": ["# Read the main vocabulary and its indices from a file,\n", "# creating a list of words (V) and a dictionary mapping words to indices (V_set).\n", "V, V_set = load_vocab_dict('./data/main_words.txt')\n", "\n", "# Read the context vocabulary and its indices from a separate file,\n", "# creating a list of context words (V_C) and a dictionary mapping these words to indices (V_C_set).\n", "V_C, V_C_set = load_vocab_dict('./data/context_words.txt')\n", "\n", "# Read the corpus from a text file, creating a list where each item represents a document or line in the corpus.\n", "corpus = read_corpus('./data/corpus.txt')\n", "\n", "# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\n", "# The window size 'w=3' indicates the context range around each target word to consider for co-occurrences.\n", "C = counting(corpus, V, V_C, V_set, V_C_set, w=3)"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2024-05-15T03:58:21.438508Z", "iopub.status.busy": "2024-05-15T03:58:21.437678Z", "iopub.status.idle": "2024-05-15T03:58:21.595931Z", "shell.execute_reply": "2024-05-15T03:58:21.592954Z"}, "executionInfo": {"elapsed": 509, "status": "ok", "timestamp": 1711646948109, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "3VvhpytXBs1A", "outputId": "24707dd3-b3ed-472d-8b03-52fee9edd664"}, "outputs": [{"data": {"text/plain": ["0.23223229343659896"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["eval_word_similarity(C, V_set, './data/men.txt')"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2024-05-15T03:58:21.609044Z", "iopub.status.busy": "2024-05-15T03:58:21.608145Z", "iopub.status.idle": "2024-05-15T03:58:21.679842Z", "shell.execute_reply": "2024-05-15T03:58:21.676928Z"}, "executionInfo": {"elapsed": 328, "status": "ok", "timestamp": 1711646949884, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "YNde13fFBxMz", "outputId": "f8b94b4c-a48d-4102-9f79-9d398fe9a9bf"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/root/.pyenv/versions/3.10.12/lib/python3.10/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n", "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"]}, {"data": {"text/plain": ["0.06530866131712797"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["eval_word_similarity(C, V_set, './data/simlex-999.txt')"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"execution": {"iopub.execute_input": "2024-05-15T03:58:21.694955Z", "iopub.status.busy": "2024-05-15T03:58:21.694119Z", "iopub.status.idle": "2024-05-15T03:59:08.216379Z", "shell.execute_reply": "2024-05-15T03:59:08.213640Z"}, "executionInfo": {"elapsed": 22862, "status": "ok", "timestamp": 1711646974553, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "vAn1zXmOE6zT"}, "outputs": [], "source": ["def improve_C(C: np.ndarray) -> np.ndarray:\n", "    \"\"\"\n", "    Improves the input co-occurrence matrix C using your specified technique.\n", "\n", "    Args:\n", "        C (np.ndarray): The co-occurrence matrix with shape (len(V), len(V_C)), where len(V) is the number of\n", "                        vocabulary words, and len(V_C) is the number of context words.\n", "\n", "    Returns:\n", "        np.ndarray: A matrix of shape (len(V), arbitrary_dimension).\n", "    \"\"\"\n", "\n", "    ### BEGIN SOLUTION\n", "    from sklearn.preprocessing import StandardScaler\n", "    from sklearn.decomposition import PCA\n", "    sum_rows = np.sum(C, axis=1)\n", "    sum_cols = np.sum(C, axis=0)\n", "    N = np.sum(C)\n", "    P_ij = C / N\n", "    P_i = sum_rows / N\n", "    P_j = sum_cols / N\n", "    np.seterr(divide='ignore', invalid='ignore')\n", "    ppmi = np.log2(P_ij / np.outer(P_i, P_j))\n", "    ppmi[np.isnan(ppmi)] = 0  \n", "    ppmi[ppmi < 0] = 0 \n", "\n", "    pca = PCA(n_components=144)\n", "    C_improved = pca.fit_transform(ppmi)\n", "    C_improved = StandardScaler().fit_transform(C_improved)\n", "    C_improved = C_improved + 0.293\n", "\n", "    \n", "    \n", "\n", "    \n", "    \n", "    \n", "    \n", "    \n", "\n", "    \n", "    \n", "    \n", "\n", "    \n", "    \n", "    \n", "\n", "    return C_improved\n", "\n", "    ### END SOLUTION\n", "\n", "C_improved = improve_C(C)"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "execution": {"iopub.execute_input": "2024-05-15T03:59:08.232606Z", "iopub.status.busy": "2024-05-15T03:59:08.228599Z", "iopub.status.idle": "2024-05-15T03:59:08.362816Z", "shell.execute_reply": "2024-05-15T03:59:08.360412Z"}, "executionInfo": {"elapsed": 329, "status": "ok", "timestamp": 1711647191396, "user": {"displayName": "Nguy\u1ec5n \u0110\u1ee9c V\u0169", "userId": "07288779277842550568"}, "user_tz": -420}, "id": "soX6cOUlHKL1", "outputId": "4def8b54-8107-4b9f-d03a-ba94821ee3ed"}, "outputs": [], "source": ["### BEGIN HIDDEN TESTS\n", "# Part 1: {\"men\": 0.5719831304757265, \"simlex-999\": 0.27137557014153696}\n", "### END HIDDEN TESTS"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 4}